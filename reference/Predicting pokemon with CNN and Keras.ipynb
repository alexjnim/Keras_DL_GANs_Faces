{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is my second attempt on this dataset. On my first attempt I tried to train model that can predict all 149 classes, but I failed because of lack of data - yes, this dataset is imbalanced and almost all classes don't have enough data for training. So, in this case I tried another approach and let's see, what we can do here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all - let's look at our data, epecially how mach images belong to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# A little bit of data exploration\n",
    "path = '../input/pokemon-generation-one/dataset/dataset' # Path to directory which contains classes\n",
    "classes = os.listdir(path) # List of all classes\n",
    "print(f'Total number of categories: {len(classes)}')\n",
    "\n",
    "# A dictionary which contains class and number of images in that class\n",
    "counts = {}\n",
    "for c in classes:\n",
    "    counts[c] = len(os.listdir(os.path.join(path, c)))\n",
    "    \n",
    "print(f'Total number of images in dataset: {sum(list(counts.values()))}')\n",
    "\n",
    "# Number of images in each clsss plot\n",
    "fig = plt.figure(figsize = (25, 5))\n",
    "sns.lineplot(x = list(counts.keys()), y = list(counts.values())).set_title('Number of images in each class')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.margins(x=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, as we can see, we have a deal with imbalanced dataset - 9 classes have a lot of pictures, another classes - very few. Moreover, as I said earlier, I tried to train model on all 149 classes, but my best results were 67% accuracy on train data and 54% on test data, we definetly need more data to train such model.\n",
    "\n",
    "So, in this case I decided to use another approach - I'll use only 5 classes with most number of pictures to train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort our \"counts\" dictionary and selecting 5 classes with most number of images\n",
    "imbalanced = sorted(counts.items(), key = lambda x: x[1], reverse = True)[:5]\n",
    "print(imbalanced)\n",
    "\n",
    "# Taking only labels, it will come in handy in future\n",
    "imbalanced = [i[0] for i in imbalanced]\n",
    "print(imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to read all images and add them to list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # List for images\n",
    "Y = [] # List for labels\n",
    "\n",
    "# Loop through all classes\n",
    "for c in classes:\n",
    "    # We take only classes that we defined in 'imbalanced' list\n",
    "    if c in imbalanced:\n",
    "        dir_path = os.path.join(path, c)\n",
    "        label = imbalanced.index(c) # Our label is an index of class in 'imbalanced' list\n",
    "        \n",
    "        # Reading, resizing and adding image and label to lists\n",
    "        for i in os.listdir(dir_path):\n",
    "            image = cv.imread(os.path.join(dir_path, i))\n",
    "            \n",
    "            try:\n",
    "                resized = cv.resize(image, (96, 96)) # Resizing images to (96, 96)\n",
    "                X.append(resized)\n",
    "                Y.append(label)\n",
    "            \n",
    "            # If we can't read image - we skip it\n",
    "            except:\n",
    "                print(os.path.join(dir_path, i), '[ERROR] can\\'t read the file')\n",
    "                continue       \n",
    "            \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look what we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting appearances of each label in labels list\n",
    "obj = Counter(Y)\n",
    "\n",
    "# Plotting number of images in each class\n",
    "fig = plt.figure(figsize = (15, 5))\n",
    "sns.barplot(x = [imbalanced[i] for i in obj.keys()], y = list(obj.values())).set_title('Number of images in each class')\n",
    "plt.margins(x=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 5 classes, each with about 300 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list with images to numpy array and reshape it \n",
    "X = np.array(X).reshape(-1, 96, 96, 3)\n",
    "\n",
    "# Scaling data in array\n",
    "X = X / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y = to_categorical(Y, num_classes = len(imbalanced))\n",
    "\n",
    "# Splitting data to train and test datasets\n",
    "# I'll use these datasets only for training, for final predictions I'll use random pictures from internet\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, shuffle = True, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we do not have too much data - we need to use data augmentation using ImageDataGenerator, which will apply random transformations to our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ImageDataGenerator Iinstance\n",
    "datagen = ImageDataGenerator(rotation_range = 45, # Degree range for random rotations\n",
    "                            zoom_range = 0.2, # Range for random zoom \n",
    "                            horizontal_flip = True, # Randomly flip inputs horizontally\n",
    "                            width_shift_range = 0.15, # Range for horizontal shift \n",
    "                            height_shift_range = 0.15, # Range for vertical shift \n",
    "                            shear_range = 0.2) # Shear Intensity\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# This piece of code can be used if you eant to look what your datagen doing with your images\n",
    "# img = X[600]\n",
    "# img = img.reshape([-1, 96, 96, 3])\n",
    "\n",
    "# i = 0\n",
    "# fig = plt.figure(figsize = (18, 8))\n",
    "\n",
    "# for i, flow in enumerate(datagen.flow(img, batch_size = 1)):\n",
    "#     fig.add_subplot(2, 5, i+1)\n",
    "#     plt.imshow(np.squeeze(flow[:, :, ::-1]))\n",
    "#     plt.axis('off')\n",
    "#     i += 1\n",
    "#     if i >= 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model, I'll use VGG-like architecture here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, padding = 'same', activation = 'relu', input_shape =(96, 96, 3), kernel_initializer = 'he_normal'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(imbalanced), activation = 'softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint('../working/best_model.hdf5', verbose = 1, monitor = 'val_accuracy', save_best_only = True)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 32), epochs = 100, validation_data = [X_test, y_test],\n",
    "                             steps_per_epoch=len(X_train) // 32, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, looks like we have a best accuracy on 66th epoch - 94.558%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig = plt.figure(figsize = (17, 4))\n",
    "    \n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'], label = 'acc')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_acc')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'accuracy')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights from best model\n",
    "model.load_weights('../working/best_model.hdf5')\n",
    "\n",
    "# Saving all model\n",
    "model.save('../working/model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict some unseen data. In this kernel I want to stick to a little bit unusual approach - I want to take some random pictures for each class from internet and try to predict them, so I quikly grabbed some urls from Google images and put them in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mewtwo = ['https://cdn.bulbagarden.net/upload/thumb/7/78/150Mewtwo.png/250px-150Mewtwo.png',\n",
    "         'https://cdn.vox-cdn.com/thumbor/sZPPvUyKyF97UEU-nNtVnC3LpF8=/0x0:1750x941/1200x800/filters:focal(878x316:1158x596)/cdn.vox-cdn.com/uploads/chorus_image/image/63823444/original.0.jpg',\n",
    "         'https://images-na.ssl-images-amazon.com/images/I/61j5ozFjJ0L._SL1024_.jpg']\n",
    "\n",
    "pikachu = ['https://lh3.googleusercontent.com/proxy/DrjDlKlu9YonKbj3iNCJNJ3DGqzy9GjeXXSUv-TcVV4UN9PMCAM5yIkGLPG7wYo3UeA4sq5OmUWM8M6K5hy2KOAhf8SOL3zPH3axb2Xo3HX2XTU8M2xW4X6lVg=w720-h405-rw',\n",
    "          'https://giantbomb1.cbsistatic.com/uploads/scale_medium/0/6087/2437349-pikachu.png',\n",
    "          'https://johnlewis.scene7.com/is/image/JohnLewis/237525467']\n",
    "\n",
    "charmander = ['https://img.pokemondb.net/artwork/large/charmander.jpg',\n",
    "             'https://www.pokemoncenter.com/wcsstore/PokemonCatalogAssetStore/images/catalog/products/P5073/701-03990/P5073_701-03990_01.jpg',\n",
    "             'https://static.posters.cz/image/750/%D0%A7%D0%B0%D1%88%D0%BA%D0%B0/pokemon-charmander-glow-i72513.jpg']\n",
    "\n",
    "bulbasaur = ['https://img.pokemondb.net/artwork/large/bulbasaur.jpg',\n",
    "            'https://ae01.alicdn.com/kf/HTB1aWullxSYBuNjSsphq6zGvVXaR/Big-Size-55-CM-Plush-Toy-Squirtle-Bulbasaur-Charmander-Toy-Sleeping-Pillow-Doll-For-Kid-Birthday.jpg',\n",
    "            'https://cdn.bulbagarden.net/upload/thumb/f/f7/Bulbasaur_Detective_Pikachu.jpg/250px-Bulbasaur_Detective_Pikachu.jpg']\n",
    "\n",
    "squirtle = ['https://assets.pokemon.com/assets/cms2/img/pokedex/full/007.png',\n",
    "           'https://cdn.vox-cdn.com/thumbor/l4cKX7ZWargjs-zlxOSW2WZVgfI=/0x0:2040x1360/1200x800/filters:focal(857x517:1183x843)/cdn.vox-cdn.com/uploads/chorus_image/image/61498573/jbareham_180925_ply0802_0030.1537570476.jpg',\n",
    "           'https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fdavidthier%2Ffiles%2F2018%2F07%2FSquirtle_Squad.jpg']\n",
    "\n",
    "test_df = [mewtwo, pikachu, charmander, bulbasaur, squirtle]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to transform these urls to arrays of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store our future data\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "for i, urls in enumerate(test_df):\n",
    "    for url in urls:        \n",
    "        r = requests.get(url, stream = True).raw\n",
    "        image = np.asarray(bytearray(r.read()), dtype=\"uint8\")\n",
    "        image = cv.imdecode(image, cv.IMREAD_COLOR)\n",
    "        val_x.append(image)\n",
    "        val_y.append(i)\n",
    "\n",
    "# plt.imshow(image[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can finaly make our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 3\n",
    "\n",
    "fig = plt.figure(figsize = (25, 25))\n",
    "\n",
    "for i, j in enumerate(zip(val_x, val_y)): # i - for subplots\n",
    "    orig = j[0] # Original, not resized image\n",
    "    label = j[1] # Label for that image\n",
    "    \n",
    "    image = cv.resize(orig, (96, 96)) # Resizing image to (96, 96)\n",
    "    image = image.reshape(-1, 96, 96, 3) / 255.0 # Reshape and scale resized image\n",
    "    preds = model.predict(image) # Predicting image\n",
    "    pred_class = np.argmax(preds) # Defining predicted class\n",
    "    \n",
    "    true_label = f'True class: {imbalanced[label]}'\n",
    "    pred_label = f'Predicted: {imbalanced[pred_class]} {round(preds[0][pred_class] * 100, 2)}%'\n",
    "    \n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(orig[:, :, ::-1])\n",
    "    plt.title(f'{true_label}\\n{pred_label}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we have 2 mistakes - Pikachu from Detective Pikachu movie was incorectly classified as Charmander and Bulbasaur (again from same move) was incorrectly classified as Mewtwo, in all other cases we got pretty good results and I think that it's not bad for such small dataset.\n",
    "\n",
    "I hope this kernel was useful, please vote if you like it and good luck in your machine learning journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
